{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8827f6e9c38914668c9f9ee83568ae81",
     "grade": false,
     "grade_id": "cell-c41639171014f7b2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import hashlib\n",
    "import math\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import barh,plot,yticks,show,grid,xlabel,figure,cla,close\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "import spacy\n",
    "\n",
    "df = pd.read_csv('datasets/twitter_rep_dem_data_small.csv')\n",
    "\n",
    "handle_remotion = lambda doc: re.subn(r'@\\w+','', doc.lower())[0]\n",
    "df['Tweet'] = df['Tweet'].map(handle_remotion)\n",
    "\n",
    "simple_tokenizer = lambda doc: \" \".join(WordPunctTokenizer().tokenize(doc))\n",
    "df['Tweet'] = df['Tweet'].map(simple_tokenizer)\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "014189de687439dcd5dc976c34659274",
     "grade": false,
     "grade_id": "cell-e068b555614ca86f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q1.\n",
    "\n",
    "You are studying Politics and want to know the type of language politicians use when they speak. To do this, you obviously went to twitter, since most politicians have become fans of making use of social media to target their electorate. You want to know the type of vocabulary politicians use, so you will start with the simplest approach you know and just extract \"meaningful\" n-grams with TF-IDF.\n",
    "\n",
    "\n",
    "### Q1.a)\n",
    "\n",
    "Implement a function to output the top k n-grams retrieved by the TF-IDF algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1351ffaf5accde9a12306d3284640823",
     "grade": false,
     "grade_id": "cell-17155c56392d07fd",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_k_best_tfidf(data, ngram_range, k):\n",
    "    \n",
    "    # vectorizer_truncated = ...\n",
    "    # ...\n",
    "    # feature_names = ...\n",
    "    # return feature_names\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "71d24e988640ff7c6876cfeb89ba907c",
     "grade": true,
     "grade_id": "cell-4279426c694d6d6e",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(hashlib.sha256(get_k_best_tfidf(train_data.Tweet, (1,1), 100)[42].encode()).hexdigest() == \"935f68319d4f227e02bfd54a0ddf85b8a242e42a4277aa5ef5eaab691710924e\")\n",
    "assert(hashlib.sha256(get_k_best_tfidf(train_data.Tweet, (1,2), 100)[42].encode()).hexdigest() == \"866ab23f02991a070ef7b06fc39ab77a0e9e840db9d0dabb204735b109d4a52c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6fd12aa9f4e1792e22fdd634876eb908",
     "grade": false,
     "grade_id": "cell-b0ec729095f7c3d0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(get_k_best_tfidf(train_data.Tweet, (1,4), 100)[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0cebf1064848624a0cca23cf3b89e1ae",
     "grade": false,
     "grade_id": "cell-565f6d25df874437",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q1.b)\n",
    "\n",
    "You got your results and were not entirely satisfied. You notice that some of your selected features are somewhat similar and that, no matter the party of a given politician, they all like to mutter the same things, hoping to get your vote and then do what they promised to the people who financed their campaigns. Fortunately, you remember learning something about stopwords.\n",
    "\n",
    "Re-implement the previous method but avoiding choosing stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6908bd9b8a00311b45f7305d9c5a606d",
     "grade": false,
     "grade_id": "cell-0dcac4c40253e789",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_k_best_tfidf_plus(data, ngram_range, k, language=None):\n",
    "    \n",
    "    # vectorizer_truncated = ...\n",
    "    # ...\n",
    "    # feature_names = ...\n",
    "    # return feature_names\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "51cd14ecd8d53535249bb6d26f2aa7e9",
     "grade": false,
     "grade_id": "cell-123df2e85e6b31e6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Verify that the results hold as before when you don't provide a language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "61d04ad93277065eb7a75e84c0138cb8",
     "grade": true,
     "grade_id": "cell-9b55532e713fb5f1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(hashlib.sha256(get_k_best_tfidf_plus(train_data.Tweet, (1,1), 100)[42].encode()).hexdigest() == \"935f68319d4f227e02bfd54a0ddf85b8a242e42a4277aa5ef5eaab691710924e\")\n",
    "assert(hashlib.sha256(get_k_best_tfidf_plus(train_data.Tweet, (1,2), 100)[42].encode()).hexdigest() == \"866ab23f02991a070ef7b06fc39ab77a0e9e840db9d0dabb204735b109d4a52c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a06affd3a80770dc5e707f432813ceb8",
     "grade": false,
     "grade_id": "cell-33ea283ae433eb61",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(get_k_best_tfidf_plus(train_data.Tweet, (1,4), 100)[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "16b122f703556bbb7fda8c10b9209d40",
     "grade": false,
     "grade_id": "cell-5a82182675077a23",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now let's tests some of our outputted words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2f7d45e4547c443392953f44dfb3c2ca",
     "grade": true,
     "grade_id": "cell-1c81e595725f5b5c",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(hashlib.sha256(get_k_best_tfidf_plus(train_data.Tweet, (1,1), 100, language='english')[42].encode()).hexdigest() == \"b2c66dfd45dd07f58d2246b695660b220ee429c6a8ba95f27e4c57f02e9d6ac8\")\n",
    "assert(hashlib.sha256(get_k_best_tfidf_plus(train_data.Tweet, (1,2), 100, language='english')[42].encode()).hexdigest() == \"b2c66dfd45dd07f58d2246b695660b220ee429c6a8ba95f27e4c57f02e9d6ac8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3aab1e631f3703267530f33826fcef24",
     "grade": false,
     "grade_id": "cell-87068d7588a45c22",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(get_k_best_tfidf_plus(train_data.Tweet, (1,4), 100, language='english')[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a7285f3bf974cdcfd5b9372dd5a4568a",
     "grade": false,
     "grade_id": "cell-0057c9f6a6750f8c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q2.\n",
    "\n",
    "After taking a careful look, you decide that, although your results are good, due to your ambitious nature, you still want to improve and get more meaningful features.\n",
    "\n",
    "Repeat Q1, but this time, instead of truncating the TF-IDF features, use the chi-squared method to get the relevant features, given the political stance of the authors of each tweet. Implement a function that outputs the most important features according to this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c0e0cfbcb9c2a7a4da5b754344893f45",
     "grade": false,
     "grade_id": "cell-ca3cb6e3d721fc9e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_k_best_chi(data, labels, ngram_range, k):\n",
    "    \n",
    "    # vectorizer = ...\n",
    "    # ...\n",
    "    # X_train = ...\n",
    "    # feature_names = ...\n",
    "    # ch2 = ...\n",
    "    # stat_X_train_chi = ...\n",
    "    # most_important = ...\n",
    "    # return most_important\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9b799b8c338dbd3c7560647f7b8692c3",
     "grade": true,
     "grade_id": "cell-dd51064dc35465dc",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(hashlib.sha256(get_k_best_chi(train_data.Tweet, train_data.Party, (1,1), 100)[42].encode()).hexdigest() == \"d6e21286621a8586f7e54720ab5a39c93acc2f4b8fba7a16ec1c24d69a08c613\")\n",
    "assert(hashlib.sha256(get_k_best_chi(train_data.Tweet, train_data.Party, (1,2), 100)[42].encode()).hexdigest() == \"c23b31a0179b550f8a18fb06bc52a26e32333540369073d646da5c84a4dc341f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "204226e76771872c34c7064c857befdf",
     "grade": false,
     "grade_id": "cell-afad1f12c84e906f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "most_important_features = get_k_best_chi(train_data.Tweet, train_data.Party, (1,2), 100)[0:10]\n",
    "print(most_important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "987355a39a1470fc043d1f850243975f",
     "grade": false,
     "grade_id": "cell-71513ce7c02dea5f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q3.\n",
    "\n",
    "You now feel confident enough to verify  if these features are in fact meaningful for classifying your data, so you decide to plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5f4e26acce10cc7a54ef80f9337a40d7",
     "grade": false,
     "grade_id": "cell-7efbb15eef09ba62",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "for feature in most_important_features:\n",
    "    print('Documents that contains the word(s) \"%s\"' % feature)\n",
    "    print('----')\n",
    "    docs = train_data.Tweet.str.lower().str.contains(feature)\n",
    "    print(str(train_data.Party[docs].value_counts()) + '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c113c89d271f689d67ebf22d0e2dde02",
     "grade": false,
     "grade_id": "cell-32c0603e66eba2ec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Which of these statements is true?\n",
    "\n",
    "**A** - If the word \"2020census\" appears in our text, we know that it must be a Democrat Tweet \n",
    "\n",
    "**B** - Republican tweets contains much more specific and therefore relevant vocabulary\n",
    "\n",
    "**C** - Chi-squared is implemented to ignore stopwords\n",
    "\n",
    "**D** - If we see the word \"betterway\" the author is probably Republican "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c91785bf5252a3e9abeead53acd8a64a",
     "grade": false,
     "grade_id": "cell-5e448e3e9a1a11fb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#answer = # Answer with a one character string, capitalized\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f7c322c80b7076ae4b9378d28e294f05",
     "grade": true,
     "grade_id": "cell-3c7d72311b6a3941",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '3f39d5c348e5b79d06e842c114e6cc571583bbf44e4b0ebfda1a01ec05745d43'\n",
    "assert hashlib.sha256(str(answer).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b4784f6a299edce9b1780877479b5d76",
     "grade": false,
     "grade_id": "cell-1dee95cc782b7b04",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q4.\n",
    "\n",
    "Back when you were taking your degree you had some algebra classes where you learned about some pretty cool concepts. You have also heard about the possibility of using them to tackle some practical issues in data science, and you wonder if they would be useful to what you are doing now. You now want try methods like SVD and PCA, but, because you don't want to waste a long time waiting for your experiments to run, you're going to start out with using a smaller dataset - the iris dataset from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "476bc686440da20328c0de57df7f55a5",
     "grade": false,
     "grade_id": "cell-fdd3e5ec37d021ae",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "\n",
    "plt.figure(2, figsize=(6,4))\n",
    "plt.clf()\n",
    "# Plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1, edgecolor='k')\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4fb4df22da7efd0d6ad28df3c28fc542",
     "grade": false,
     "grade_id": "cell-8386eb7c83144076",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "You first verified that the data is not that easy to separate taking two of your features, so you now want to see the results for the first few components. Implement SVD decomposition to return a reduced version of your data and see the results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "51b41c5a325a3ff88069320feb37dfa2",
     "grade": false,
     "grade_id": "cell-615fa1a7ad60dda0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def svd_decomposition(A, n_components):\n",
    "\n",
    "    # AT = ...\n",
    "    # AAT = ...\n",
    "    # ATA = ...\n",
    "    \n",
    "    # lmbU, U = ...\n",
    "    # lmbV, V = ...\n",
    "\n",
    "    #S_shape = ...\n",
    "    #lmb = ...\n",
    "    #S = ...\n",
    "    \n",
    "    #reduction = ...\n",
    "    #return reduction\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e7e3e95db5bd905db99ac44151f02ee7",
     "grade": false,
     "grade_id": "cell-d70dfff527a003c3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_reduced = svd_decomposition(iris.data, 2)\n",
    "\n",
    "x_min, x_max = X_reduced[:, 0].min() - .5, X_reduced[:, 0].max() + .5\n",
    "y_min, y_max = X_reduced[:, 1].min() - .5, X_reduced[:, 1].max() + .5\n",
    "\n",
    "plt.figure(2, figsize=(6,4))\n",
    "plt.clf()\n",
    "\n",
    "# Plot the training points\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y, cmap=plt.cm.Set1, edgecolor='k')\n",
    "plt.xlabel('SVD 1')\n",
    "plt.ylabel('SVD 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ed75c54c10b0702f03f5ff665743ff9d",
     "grade": false,
     "grade_id": "cell-288747944f9bf58e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "You should see a much better separation with SVD than you saw before. If you don't, something is not right. Let's check if the components you obtained are right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "378d3bda5273b0284442728d97dbefee",
     "grade": true,
     "grade_id": "cell-baf6a0f82935e3ac",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_reduced = svd_decomposition(iris.data, 2)\n",
    "\n",
    "assert math.isclose(X_reduced[:, 0].sum(axis=0), 1151.87905039)\n",
    "assert math.isclose(X_reduced[:, 1].sum(axis=0), 38.48015192)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e3c8524ec8d03ebeb83bfdb3635c6db4",
     "grade": false,
     "grade_id": "cell-13af24e985feec28",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q5.\n",
    "\n",
    "After testing SVD you also want to test the other cool-sounding method, PCA. Implement it and see how its results compare with the the ones obtained for SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0fd01b6129dde9278899ea74a33a04b9",
     "grade": false,
     "grade_id": "cell-f882c24a78354337",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def pca_reduction(A, n_components):\n",
    "    \n",
    "    # u = ...\n",
    "    # covA = ...\n",
    "    # lmbV, V = ...\n",
    "    # V_red = ...\n",
    "    # reduction = ...\n",
    "    # return reduction  \n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fcb062557ce4104527c9a6d658cdf958",
     "grade": false,
     "grade_id": "cell-9022e81c957801b7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_reduced_pca = pca_reduction(iris.data - iris.data.mean(axis=0), 2)\n",
    "\n",
    "x_min, x_max = X_reduced_pca[:, 0].min() - .5, X_reduced_pca[:, 0].max() + .5\n",
    "y_min, y_max = X_reduced_pca[:, 1].min() - .5, X_reduced_pca[:, 1].max() + .5\n",
    "\n",
    "plt.figure(2, figsize=(6,4))\n",
    "plt.clf()\n",
    "# Plot the training points\n",
    "plt.scatter(X_reduced_pca[:, 0], X_reduced_pca[:, 1], c=y, cmap=plt.cm.Set1, edgecolor='k')\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6f9f50ddf82bc2f26430fe628ea97a32",
     "grade": false,
     "grade_id": "cell-3db7791695b0da91",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "And finally, to make sure everything is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bdd66c0d6bf5f5fd5f1c7d4bff328e8f",
     "grade": true,
     "grade_id": "cell-3fabdbdf0da61899",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert math.isclose(X_reduced_pca[42, 0], -2.998296442832354, abs_tol=1e-6)\n",
    "assert math.isclose(X_reduced_pca[42, 1], 0.3343075745907761, abs_tol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "15307cb3cc2dac10f04fb107d95d4a68",
     "grade": false,
     "grade_id": "cell-416b2e2905e48fec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q6.\n",
    "\n",
    "Now that you have mastered the art of using algebra methods for dimensionality reduction, pick the only true statement in the following questions:\n",
    "\n",
    "\n",
    "### Q6.a)\n",
    "\n",
    "**E** - SVD and PCA are essentialy the same method\n",
    "\n",
    "**F** - SVD requires us to center the data before computing a decomposition\n",
    "\n",
    "**G** - PCA can be solved by applying SVD internally\n",
    "\n",
    "**H** - PCA and SVD are not the same method but return the same principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5e3c0816d70e78420879dc02e70f4915",
     "grade": false,
     "grade_id": "cell-dec9bff37d676bcb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#answer = # Answer with a one character string, capitalized\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d9427a6d4e659a18f765034039d31e59",
     "grade": true,
     "grade_id": "cell-0abe1a2e6fb7cbe0",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '333e0a1e27815d0ceee55c473fe3dc93d56c63e3bee2b3b4aee8eed6d70191a3'\n",
    "assert hashlib.sha256(str(answer).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e8828a6cc43d7ccddabdb51887a18eb1",
     "grade": false,
     "grade_id": "cell-51cb77cc03bb59e8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Q6.b)\n",
    "\n",
    "**I** - The sum of the eigenvalues of a data matrix equals that data variance\n",
    "\n",
    "**J** - SVD requires us to center the data before computing a decomposition\n",
    "\n",
    "**K** - The sum of the eigenvalues of the covariance matrix of a given data matrix equals that data variance\n",
    "\n",
    "**L** - The singular value decomposition generates four matrices that multiplied reconstruct the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f273e48ad93051c2b6442f359e2ef972",
     "grade": false,
     "grade_id": "cell-f5662a10917b237a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#answer = # Answer with a one character string, capitalized\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8c0fc81d15adf01af23130ebbcadbe52",
     "grade": true,
     "grade_id": "cell-33058c9dbf1e5c97",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = '86be9a55762d316a3026c2836d044f5fc76e34da10e1b45feee5f18be7edb177'\n",
    "assert hashlib.sha256(str(answer).encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "16f629eb5d25c1ad969985d144491412",
     "grade": false,
     "grade_id": "cell-94dca9bb273ba2cb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q7.\n",
    "\n",
    "After a long day looking at politicians tweeting as often as CMTV finds a new disaster to report and then trying to separate flowers with the powers of mathematics you wonder what is the meaning of life after all. You mistakenly say it aloud and a guy suspiciously looking like Tomas Mikolov starts muttering a long sequence of numbers. The thought that maybe numbers and vectors are really the answer goes through your head. Then it comes to you that you have heard in the past about something called embeddings and how they are able to incorporate the meaning of words into vectors and you want to test it.\n",
    "\n",
    "Before doing so, you need a way to measure the distance between these vectors and therefore, between words. Start by implementing a function that is able to measure the difference of cosine similarity between the vectors of two words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "36b5aa962fb1c565d213ff8ba1e074a5",
     "grade": false,
     "grade_id": "cell-d5a496b5581b31ea",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def vec(s):\n",
    "    return nlp.vocab[s].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a134ab4b2599065b473f64ebe98601a5",
     "grade": false,
     "grade_id": "cell-24db69517366bdc8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def cosine_diff(vector_pair_1, vector_pair_2):\n",
    "    \n",
    "    #v1, v2 = vector_pair_1\n",
    "    #if ...:\n",
    "    #    cosine_1 = ...\n",
    "    #else:\n",
    "    #    cosine_1 = ...\n",
    "    #v3, v4 = vector_pair_2\n",
    "    #if ...:\n",
    "    #    cosine_2 = ...\n",
    "    #else:\n",
    "    #    cosine_2 = ...\n",
    "        \n",
    "    #return cosine_1 - cosine_2\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6def280158d7c85aec7b57deb311601e",
     "grade": true,
     "grade_id": "cell-f52da173a887ccbd",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(math.isclose(cosine_diff((vec('man'), vec('boy')), (vec('man'), vec('girl'))), 0.13031119, abs_tol=1e-7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1530ef5abbf26182de599d85847a3e17",
     "grade": false,
     "grade_id": "cell-be19a16cbe0dafbc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q8.\n",
    "\n",
    "What the heck? It seems to be true. These weird looking vectors are indeed able to say that the word boy is closer to the word man than the word girl is. Hmmm.. you decide to investigate a little bit further. How do you know they're not foooling you? Let's see if they are able to infer some very simple associations between words. Implement the necessary code to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "35df05221a5d27042a517aba6afe6b90",
     "grade": false,
     "grade_id": "cell-a818c1987dc990ea",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def cosine(v1, v2):\n",
    "    if norm(v1) > 0 and norm(v2) > 0:\n",
    "        return dot(v1, v2) / (norm(v1) * norm(v2))\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def spacy_closest(token_list, vec_to_check, n=10, dont_include_list=[]):\n",
    "    return sorted([x for x in token_list if x not in dont_include_list],\n",
    "                  key=lambda x: cosine(vec_to_check, vec(x)),\n",
    "                  reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6652e6110cf0b94bcad11500295db5f1",
     "grade": false,
     "grade_id": "cell-6167b34397243ec7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit_transform(train_data.Tweet)\n",
    "\n",
    "tweet_vocab = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "888731c90863a58107a61a6b38dfa31e",
     "grade": false,
     "grade_id": "cell-8df0ab8b60111598",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def word_vector_arithmetic(token_list, positive_vecs=[], negative_vecs=[], n=10, dont_include_list=[]):\n",
    " \n",
    "    #vec_to_check = ...\n",
    "    #for vec in positive_vecs:\n",
    "    #    if vec_to_check is None:\n",
    "    #        vec_to_check = ...\n",
    "    #    else:\n",
    "    #        vec_to_check += ...\n",
    "    #for vec in negative_vecs:\n",
    "    #    vec_to_check -= ...\n",
    "    #return spacy_closest(...)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0de40d063b506e45a53c78e2aaa96475",
     "grade": true,
     "grade_id": "cell-efb61c0c575def1a",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "closest_word = word_vector_arithmetic(tweet_vocab.keys(),\n",
    "                                      positive_vecs=[vec('prince'), vec('woman')],\n",
    "                                      negative_vecs=[vec('man')],\n",
    "                                      dont_include_list=['prince', 'woman', 'man'])[0]\n",
    "\n",
    "assert(closest_word == 'princess')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "772ebcdccf0f04f020b66e4686b8e8c1",
     "grade": false,
     "grade_id": "cell-dee81471516926c5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Maybe that Tomas Mikolov fellow wasn't muttering those numbers in vain.. Well, but to know that you will have to keep studying about the topic :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
